{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio file to SRT subtitles file\n",
    "\n",
    "## Requirements\n",
    "\n",
    "The requirements for this workbook to work are:\n",
    "- An Azure cognitive service with a cognitive service key\n",
    "- An input video file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "\n",
    "This section installs the required libraries for the code to run:\n",
    "- [azure-cognitiveservices-speech](https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-speech/azure.cognitiveservices.speech?view=azure-python): is used to communicate with the Azure Speech API\n",
    "- [python-dotenv](https://pypi.org/project/python-dotenv/): is used to read the .env file containing the Cognitive Service keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-cognitiveservices-speech\n",
    "! pip install python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings\n",
    "\n",
    "You probably should not put your settings in this file. Instead, put them in a .env file and import them from there.\n",
    "\n",
    "Your .env file should look like this:\n",
    "```\n",
    "SPEECH_KEY=<your-speech-key>\n",
    "SPEECH_REGION=<your-speech-region>\n",
    "SPEECH_FILE=<your-source-video-file-path>\n",
    "SPEECH_LANGUAGE=<your-speech-language>\n",
    "```\n",
    "\n",
    "Then we create a settings variable containing the values from the .env file.\n",
    "- `key`: Azure Cognitive service key\n",
    "- `region`: Azure cognitive service region\n",
    "- `speechFile`: Name of the video file to convert to SRT subtitles\n",
    "- `language`: Source language of the file\n",
    "- `fileName`: Name of the output audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import re\n",
    "load_dotenv(override=True)\n",
    "\n",
    "settings = {\n",
    "    'key': os.environ.get('SPEECH_KEY'),\n",
    "    'region': os.environ.get('SPEECH_REGION'),\n",
    "    'speechFile': os.getenv('SPEECH_FILE'), # Feel free to hardcode the file path\n",
    "    'language': os.environ.get('SPEECH_LANGUAGE'),   # Feel free to hardcode the language\n",
    "    'fileName': \"./audio.wav\"\n",
    "}\n",
    "# Create fileName by taking the leaf of the path from speechFile and replacing the extension with .wav using regex\n",
    "settings['fileName'] = f\"./outputs/{settings['speechFile'].split('/')[-1]}\"\n",
    "settings['fileName'] = re.sub(r'\\.[^\\.]+$', '.wav', settings['fileName'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helpers\n",
    "\n",
    "Create a function to convert nanoseconds to timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def toTimeStamp(nano):\n",
    "    nano = nano*100\n",
    "    hour = math.floor(nano/3600000000000)\n",
    "    nano = nano -hour*3600000000000\n",
    "    minutes = math.floor(nano/60000000000)\n",
    "    nano = nano - minutes*60000000000\n",
    "    seconds = math.floor(nano/1000000000)\n",
    "    nano = nano - seconds*1000000000\n",
    "    milliseconds = math.floor(nano/1000000)\n",
    "    timestamp = \"{0:02d}:{1:02d}:{2:02d},{3:03d}\".format(hour,minutes,seconds,milliseconds)\n",
    "    return timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Video Audio\n",
    "\n",
    "In this section, we will use ffmpeg to extract the audio from the video.\n",
    "\n",
    "> **Note**: ffmpeg needs to be installed in the *ffmpeg* folder in this project.\n",
    "> You can download it from [here](https://ffmpeg.org/download.html).\n",
    "> If you have ffmpeg installed in your system, you can either update the command below to use it or, if its path is in the environment PATH, you can just replace the path below with `ffmpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "command = f\"./ffmpeg/ffmpeg -y -i '{settings['speechFile']}' -ab 160k -ac 2 -ar 44100 -vn '{settings['fileName']}'\"\n",
    "\n",
    "subprocess.call(command, shell=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate captions from audio file\n",
    "\n",
    "This section will use the Azure Speech API to generate captions from the audio file.\n",
    "\n",
    "An SRT caption file is in the format:\n",
    "```\n",
    "<number>\n",
    "<start timestamp> --> <end timestamp>\n",
    "<caption>\n",
    "\n",
    "\n",
    "<number>\n",
    "<start timestamp> --> <end timestamp>\n",
    "<caption>\n",
    "\n",
    "\n",
    "1\n",
    "00:00:00,000 --> 00:00:02,000\n",
    "Hello!\n",
    "\n",
    "2\n",
    "00:00:02,000 --> 00:00:04,000\n",
    "This is a test.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the transcript using Speech Services\n",
    "\n",
    "This section will use the Azure Speech API to generate captions from the audio file.\n",
    "\n",
    "The result of the speech API is a list of possible recognized words/sentences. Each word/sentence has its own confidence score, and timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import time\n",
    "\n",
    "\n",
    "def get_transcript_from_file():\n",
    "    print(\"===================================\")\n",
    "    print (\"Processing \"+settings['fileName'])\n",
    "    print(\"===================================\")\n",
    "\n",
    "    # Creates an instance of a speech config with specified subscription key and service region.\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=settings['key'], region=settings['region'])\n",
    "    speech_config.request_word_level_timestamps()\n",
    "    speech_config.set_property(property_id=speechsdk.PropertyId.SpeechServiceResponse_OutputFormatOption, value=\"detailed\")\n",
    "\n",
    "    # Creates a speech recognizer using file as audio input.\n",
    "    audio_input = speechsdk.audio.AudioConfig(filename=settings['fileName'])\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, language=settings['language'], audio_config=audio_input)\n",
    "    \n",
    "    # initialize some variables\n",
    "    results = []\n",
    "    done = False\n",
    "\n",
    "    # Event handler to add event to the result list\n",
    "    def handleResult(evt):\n",
    "        import json\n",
    "        nonlocal results\n",
    "        results.append(json.loads(evt.result.json))\n",
    "        \n",
    "        print('RECOGNIZED: {}'.format(evt)) # print the result (optional, otherwise it can run for a few minutes without output)\n",
    "\n",
    "        # result object\n",
    "        res = {'text':evt.result.test, 'timestamp': evt.result.offset, 'duration':evt.result.duration}\n",
    "\n",
    "        if (evt.result.text != \"\"):\n",
    "            results.append(res)\n",
    "            print(evt.result)\n",
    "\n",
    "    \n",
    "    # Event handler to check if the recognizer is done\n",
    "    def stop_cb(evt):\n",
    "        print('CLOSING on {}'.format(evt))\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "        nonlocal done\n",
    "        done= True\n",
    "\n",
    "    # Connect callbacks to the events fired by the speech recognizer & displays the info/status\n",
    "    # Ref:https://docs.microsoft.com/en-us/python/api/azure-cognitiveservices-speech/azure.cognitiveservices.speech.eventsignal?view=azure-python   \n",
    "    # speech_recognizer.recognizing.connect(lambda evt: print('RECOGNIZING: {}'.format(evt)))\n",
    "    # speech_recognizer.recognized.connect(lambda evt: print('RECOGNIZED: {}'.format(evt)))\n",
    "    speech_recognizer.session_started.connect(lambda evt: print('SESSION STARTED: {}'.format(evt)))\n",
    "    # speech_recognizer.session_stopped.connect(lambda evt: print('SESSION STOPPED {}'.format(evt)))\n",
    "    # speech_recognizer.canceled.connect(lambda evt: print('CANCELED {}'.format(evt)))\n",
    "    speech_recognizer.recognized.connect(handleResult) \n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "\n",
    "    # Starts continuous speech recognition\n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "\n",
    "    # Wait for speech recognition to complete\n",
    "    while not done:\n",
    "        time.sleep(1)\n",
    "    \n",
    "    return results\n",
    "\n",
    "results = get_transcript_from_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the individual words caption\n",
    "\n",
    "This is useful for video editing, you get to have a caption for every word, that way when you cut off a word, you do not need to edit the entire caption, or risk losing the caption/re-time the caption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "captions = \"\" # this is used to store the output SRT data\n",
    "i=0 # this is the index of the result (<number> in the SRT example above)\n",
    "\n",
    "for result in results:\n",
    "    if (result['RecognitionStatus']!='InitialSilenceTimeout'):\n",
    "        res= result[\"NBest\"][0]\n",
    "        try:\n",
    "            for word in res[\"Words\"]:\n",
    "                i+=1\n",
    "                start = toTimeStamp(word[\"Offset\"])\n",
    "                end = toTimeStamp(word[\"Offset\"]+word[\"Duration\"])\n",
    "                captions += \"\"\"{0}\n",
    "{1} --> {2}\n",
    "{3}\n",
    "\n",
    "\"\"\".format(i,start,end,word[\"Word\"])\n",
    "        except KeyError:\n",
    "            null = \"\"\n",
    "\n",
    "f = open(\"{0}-caption-words.srt\".format(settings['fileName']), \"w\")\n",
    "f.write(captions)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Entire Caption\n",
    "\n",
    "Same as the previous section, but this time we will create a single caption for an entire sentence. This is better for a final output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "captions = \"\"\n",
    "i=0\n",
    "row = 0\n",
    "for result in results:\n",
    "    try:\n",
    "        i+=1\n",
    "        start = toTimeStamp(result[\"Offset\"])\n",
    "        end = toTimeStamp(result[\"Offset\"]+result[\"Duration\"])\n",
    "        captions += \"\"\"{0}\n",
    "{1} --> {2}\n",
    "{3}\n",
    "\n",
    "\"\"\".format(i,start,end,result[\"DisplayText\"])\n",
    "    except KeyError:\n",
    "        i-=1\n",
    "\n",
    "f = open(\"{0}-caption.srt\".format(settings['fileName']), \"w\")\n",
    "f.write(captions)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Text\n",
    "\n",
    "This is just one big string of all the words/sentences without timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "outputText = \"\"\n",
    "i=0\n",
    "row = 0\n",
    "for result in results:\n",
    "    try:\n",
    "        i+=1\n",
    "        start = toTimeStamp(result[\"Offset\"])\n",
    "        end = toTimeStamp(result[\"Offset\"]+result[\"Duration\"])\n",
    "        outputText += \" {0}\".format(result[\"DisplayText\"])\n",
    "    except KeyError:\n",
    "        i-=1\n",
    "\n",
    "f = open(\"{0}-text.txt\".format(settings['fileName']), \"w\")\n",
    "f.write(outputText)\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
